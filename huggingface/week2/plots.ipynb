{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GIF guardado como output.gif\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def create_gif_from_frames(folder_path, output_gif, fps=10):\n",
    "    \"\"\"\n",
    "    Crea un GIF a partir de una carpeta con frames (.png).\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Ruta de la carpeta con los frames.\n",
    "        output_gif (str): Nombre del GIF de salida (ej. 'output.gif').\n",
    "        fps (int): Cu√°ntos frames por segundo (mayor valor = animaci√≥n m√°s r√°pida).\n",
    "    \"\"\"\n",
    "    frames = sorted(\n",
    "        [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".png\")]\n",
    "    )\n",
    "\n",
    "    if not frames:\n",
    "        print(\"‚ùå No se encontraron archivos .png en la carpeta.\")\n",
    "        return\n",
    "\n",
    "    images = [Image.open(frame) for frame in frames]\n",
    "    \n",
    "    # Guardar el GIF\n",
    "    images[0].save(output_gif, save_all=True, append_images=images[1:], duration=1000//fps, loop=0)\n",
    "    print(f\"‚úÖ GIF guardado como {output_gif}\")\n",
    "\n",
    "# üìå Uso:\n",
    "create_gif_from_frames(frames_path, \"output.gif\", fps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GIF guardado como output.gif\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "\n",
    "def sorted_nicely(file_list):\n",
    "    \"\"\" Ordena archivos con n√∫meros correctamente (ej. frame_1.png, frame_2.png, ...). \"\"\"\n",
    "    def convert(text):\n",
    "        return int(text) if text.isdigit() else text.lower()\n",
    "    \n",
    "    def alphanum_key(key):\n",
    "        return [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    \n",
    "    return sorted(file_list, key=alphanum_key)\n",
    "\n",
    "def create_gif_from_frames(folder_path, output_gif, fps=10):\n",
    "    \"\"\"\n",
    "    Crea un GIF a partir de una carpeta con frames (.png), asegurando el orden correcto.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Ruta de la carpeta con los frames.\n",
    "        output_gif (str): Nombre del GIF de salida (ej. 'output.gif').\n",
    "        fps (int): Cu√°ntos frames por segundo (mayor valor = animaci√≥n m√°s r√°pida).\n",
    "    \"\"\"\n",
    "    frames = sorted_nicely(\n",
    "        [f for f in os.listdir(folder_path) if f.endswith(\".png\")]\n",
    "    )\n",
    "\n",
    "    if not frames:\n",
    "        print(\"‚ùå No se encontraron archivos .png en la carpeta.\")\n",
    "        return\n",
    "\n",
    "    images = [Image.open(os.path.join(folder_path, frame)) for frame in frames]\n",
    "\n",
    "    # Guardar el GIF\n",
    "    images[0].save(output_gif, save_all=True, append_images=images[1:], duration=1000//fps, loop=0)\n",
    "    print(f\"‚úÖ GIF guardado como {output_gif}\")\n",
    "\n",
    "# üìå Uso:\n",
    "frames_path = '/Users/arnaubarrera/Desktop/MSc Computer Vision/C5. Visual Recognition/mcv-c5-group-3/segmentation_results/segmentation_result'\n",
    "create_gif_from_frames(frames_path, \"output.gif\", fps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from typing import Dict, Optional, List, Union\n",
    "from datetime import datetime\n",
    "\n",
    "def calculate_global_map_from_files(\n",
    "    predictions_dir: str,\n",
    "    ground_truth_dir: str,\n",
    "    output_file: str = \"instance_segmentation_results.txt\",\n",
    "    matching_method: str = \"index\",\n",
    "    video_ids: Optional[List[str]] = None\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Calcula m√©tricas globales de instance segmentation y genera un archivo TXT con los resultados.\n",
    "    \n",
    "    Args:\n",
    "        predictions_dir: Directorio que contiene los archivos JSON de predicciones.\n",
    "        ground_truth_dir: Directorio que contiene los archivos JSON de ground truth.\n",
    "        output_file: Ruta del archivo de salida TXT (default: \"instance_segmentation_results.txt\").\n",
    "        pred_pattern: Patr√≥n glob para identificar archivos de predicciones (default: \"coco_preds_*.json\").\n",
    "        gt_pattern: Patr√≥n glob para identificar archivos de ground truth (default: \"gt_coco_*.json\").\n",
    "        matching_method: M√©todo para emparejar archivos (\"index\" o \"name\").\n",
    "        video_ids: Lista opcional de IDs de v√≠deo para filtrar (e.j. ['0000', '0001', '0010']).\n",
    "                   Si es None, se procesar√°n todos los v√≠deos.\n",
    "    \n",
    "    Returns:\n",
    "        Dict: Diccionario con m√©tricas globales.\n",
    "    \"\"\"\n",
    "    pred_pattern = \"preds_coco_*.json\"\n",
    "    gt_pattern = \"gt_coco_*.json\"\n",
    "    \n",
    "    # Obtener listas de archivos\n",
    "    pred_files = sorted(glob.glob(os.path.join(predictions_dir, pred_pattern)))\n",
    "    gt_files = sorted(glob.glob(os.path.join(ground_truth_dir, gt_pattern)))\n",
    "    \n",
    "    if not pred_files:\n",
    "        raise ValueError(f\"No se encontraron archivos de predicciones con el patr√≥n {pred_pattern} en {predictions_dir}\")\n",
    "    if not gt_files:\n",
    "        raise ValueError(f\"No se encontraron archivos de ground truth con el patr√≥n {gt_pattern} en {ground_truth_dir}\")\n",
    "    \n",
    "    print(f\"Encontrados {len(pred_files)} archivos de predicciones y {len(gt_files)} archivos de ground truth\")\n",
    "    \n",
    "    # Emparejar archivos de predicciones con ground truth\n",
    "    paired_files = []\n",
    "    \n",
    "    if matching_method == \"index\":\n",
    "        # Extraer √≠ndices num√©ricos de los nombres de archivo\n",
    "        pred_indices = {}\n",
    "        gt_indices = {}\n",
    "        \n",
    "        for pred_file in pred_files:\n",
    "            # Extraer el √≠ndice (ej: \"coco_preds_0000.json\" -> \"0000\")\n",
    "            basename = os.path.basename(pred_file)\n",
    "            index_part = basename.split(\"_\")[-1].split(\".\")[0]\n",
    "            pred_indices[index_part] = pred_file\n",
    "        \n",
    "        for gt_file in gt_files:\n",
    "            # Extraer el √≠ndice (ej: \"gt_coco_0000.json\" -> \"0000\")\n",
    "            basename = os.path.basename(gt_file)\n",
    "            index_part = basename.split(\"_\")[-1].split(\".\")[0]\n",
    "            gt_indices[index_part] = gt_file\n",
    "        \n",
    "        # Determinar los √≠ndices a procesar\n",
    "        if video_ids:\n",
    "            # Filtrar por los IDs de v√≠deo proporcionados\n",
    "            valid_indices = [idx for idx in video_ids if idx in pred_indices and idx in gt_indices]\n",
    "            if not valid_indices:\n",
    "                raise ValueError(f\"Ninguno de los video_ids proporcionados ({video_ids}) corresponde a archivos v√°lidos\")\n",
    "            print(f\"Filtrando por {len(valid_indices)} IDs de v√≠deo especificados\")\n",
    "        else:\n",
    "            # Usar todos los √≠ndices coincidentes\n",
    "            valid_indices = set(pred_indices.keys()) & set(gt_indices.keys())\n",
    "        \n",
    "        # Emparejar por √≠ndice\n",
    "        paired_files = [(pred_indices[idx], gt_indices[idx]) for idx in sorted(valid_indices)]\n",
    "        \n",
    "    elif matching_method == \"name\":\n",
    "        # Emparejar por nombre base\n",
    "        pred_dict = {os.path.splitext(os.path.basename(f))[0]: f for f in pred_files}\n",
    "        gt_dict = {os.path.splitext(os.path.basename(f))[0]: f for f in gt_files}\n",
    "        \n",
    "        # Encontrar pares coincidentes, filtrando por video_ids si es necesario\n",
    "        for pred_name, pred_file in pred_dict.items():\n",
    "            for gt_name, gt_file in gt_dict.items():\n",
    "                # Extraer ID del v√≠deo del nombre del archivo\n",
    "                if \"_\" in pred_name:\n",
    "                    video_id = pred_name.split(\"_\")[-1]\n",
    "                else:\n",
    "                    video_id = pred_name\n",
    "                \n",
    "                if pred_name == gt_name.replace(\"gt_\", \"\"):\n",
    "                    # Si se proporcionaron video_ids, verificar si este v√≠deo est√° en la lista\n",
    "                    if video_ids and video_id not in video_ids:\n",
    "                        continue\n",
    "                    \n",
    "                    paired_files.append((pred_file, gt_file))\n",
    "                    break\n",
    "    else:\n",
    "        raise ValueError(f\"M√©todo de emparejamiento no reconocido: {matching_method}\")\n",
    "    \n",
    "    if not paired_files:\n",
    "        if video_ids:\n",
    "            raise ValueError(f\"No se encontraron parejas coincidentes para los IDs de v√≠deo: {video_ids}\")\n",
    "        else:\n",
    "            raise ValueError(\"No se encontraron parejas coincidentes de archivos de predicci√≥n y ground truth\")\n",
    "    \n",
    "    print(f\"Se emparejaron {len(paired_files)} archivos\")\n",
    "    \n",
    "    # Guardar lista de archivos procesados\n",
    "    processed_files = [f\"- {os.path.basename(p)} ‚Üî {os.path.basename(g)}\" for p, g in paired_files]\n",
    "    \n",
    "    # Inicializar estructuras para datos globales\n",
    "    global_predictions = []\n",
    "    global_gt = {\n",
    "        'images': [],\n",
    "        'annotations': [],\n",
    "        'categories': []\n",
    "    }\n",
    "    \n",
    "    next_image_id = 1\n",
    "    next_annotation_id = 1\n",
    "    image_id_mapping = {}  # Mapeo de IDs originales a IDs globales\n",
    "    \n",
    "    # Procesar cada pareja de archivos\n",
    "    for pred_file, gt_file in paired_files:\n",
    "        print(f\"Procesando: {os.path.basename(pred_file)} y {os.path.basename(gt_file)}\")\n",
    "        \n",
    "        # Cargar predicciones\n",
    "        with open(pred_file, 'r') as f:\n",
    "            video_predictions = json.load(f)\n",
    "        \n",
    "        # Cargar ground truth\n",
    "        with open(gt_file, 'r') as f:\n",
    "            gt_data = json.load(f)\n",
    "        \n",
    "        # Extraer categor√≠as del primer GT si a√∫n no las tenemos\n",
    "        if not global_gt['categories'] and 'categories' in gt_data:\n",
    "            global_gt['categories'] = gt_data['categories']\n",
    "        \n",
    "        # Procesar im√°genes del ground truth\n",
    "        for img in gt_data.get('images', []):\n",
    "            original_img_id = img['id']\n",
    "            if original_img_id not in image_id_mapping:\n",
    "                image_id_mapping[original_img_id] = next_image_id\n",
    "                next_image_id += 1\n",
    "                \n",
    "            # A√±adir imagen con ID global\n",
    "            new_img = img.copy()\n",
    "            new_img['id'] = image_id_mapping[original_img_id]\n",
    "            global_gt['images'].append(new_img)\n",
    "        \n",
    "        # Procesar anotaciones del ground truth\n",
    "        for ann in gt_data.get('annotations', []):\n",
    "            original_img_id = ann['image_id']\n",
    "            if original_img_id in image_id_mapping:\n",
    "                # A√±adir anotaci√≥n con ID global\n",
    "                new_ann = ann.copy()\n",
    "                new_ann['id'] = next_annotation_id\n",
    "                new_ann['image_id'] = image_id_mapping[original_img_id]\n",
    "                global_gt['annotations'].append(new_ann)\n",
    "                next_annotation_id += 1\n",
    "        \n",
    "        # Procesar predicciones\n",
    "        for pred in video_predictions:\n",
    "            original_img_id = pred['image_id']\n",
    "            if original_img_id in image_id_mapping:\n",
    "                # A√±adir predicci√≥n con ID global\n",
    "                new_pred = pred.copy()\n",
    "                new_pred['image_id'] = image_id_mapping[original_img_id]\n",
    "                global_predictions.append(new_pred)\n",
    "    \n",
    "    # Verificar que tenemos datos para evaluar\n",
    "    if not global_predictions:\n",
    "        raise ValueError(\"No se pudieron extraer predicciones con IDs de imagen v√°lidos\")\n",
    "    \n",
    "    if not global_gt['annotations']:\n",
    "        raise ValueError(\"No se pudieron extraer anotaciones de ground truth con IDs de imagen v√°lidos\")\n",
    "    \n",
    "    # Estad√≠sticas sobre los datos combinados\n",
    "    num_predictions = len(global_predictions)\n",
    "    num_images = len(global_gt['images'])\n",
    "    num_annotations = len(global_gt['annotations'])\n",
    "    \n",
    "    print(f\"Datos combinados: {num_predictions} predicciones, {num_images} im√°genes, \"\n",
    "          f\"{num_annotations} anotaciones ground truth\")\n",
    "    \n",
    "    # Evaluar usando la API COCOeval\n",
    "    coco_gt = COCO()\n",
    "    coco_gt.dataset = global_gt\n",
    "    coco_gt.createIndex()\n",
    "    \n",
    "    coco_dt = coco_gt.loadRes(global_predictions)\n",
    "    \n",
    "    # Inicializar evaluador\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='segm')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    \n",
    "    # Extraer m√©tricas\n",
    "    metrics = {\n",
    "        'mAP': coco_eval.stats[0],  # mAP @ IoU=0.50:0.95\n",
    "        'mAP_50': coco_eval.stats[1],  # mAP @ IoU=0.50\n",
    "        'mAP_75': coco_eval.stats[2],  # mAP @ IoU=0.75\n",
    "        'mAP_small': coco_eval.stats[3],  # mAP para objetos peque√±os\n",
    "        'mAP_medium': coco_eval.stats[4],  # mAP para objetos medianos\n",
    "        'mAP_large': coco_eval.stats[5],  # mAP para objetos grandes\n",
    "        'AR_max1': coco_eval.stats[6],  # AR dado 1 detecci√≥n por imagen\n",
    "        'AR_max10': coco_eval.stats[7],  # AR dado 10 detecciones por imagen\n",
    "        'AR_max100': coco_eval.stats[8],  # AR dado 100 detecciones por imagen\n",
    "        'AR_small': coco_eval.stats[9],  # AR para objetos peque√±os\n",
    "        'AR_medium': coco_eval.stats[10],  # AR para objetos medianos\n",
    "        'AR_large': coco_eval.stats[11],  # AR para objetos grandes\n",
    "        'num_videos': len(paired_files),  # N√∫mero de videos procesados\n",
    "        'num_images': num_images,\n",
    "        'num_predictions': num_predictions,\n",
    "        'num_annotations': num_annotations\n",
    "    }\n",
    "    \n",
    "    # Obtener categor√≠as procesadas\n",
    "    categories = []\n",
    "    if global_gt['categories']:\n",
    "        categories = [f\"{cat['id']}: {cat['name']}\" for cat in global_gt['categories']]\n",
    "    \n",
    "    # Escribir resultados en archivo TXT\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.write(f\"RESULTADOS DE EVALUACI√ìN DE INSTANCE SEGMENTATION\\n\")\n",
    "        f.write(f\"Fecha/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"RESUMEN DE DATOS\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        f.write(f\"Directorio de predicciones: {os.path.abspath(predictions_dir)}\\n\")\n",
    "        f.write(f\"Directorio de ground truth: {os.path.abspath(ground_truth_dir)}\\n\")\n",
    "        \n",
    "        # A√±adir informaci√≥n sobre filtrado por video_ids si se proporcion√≥\n",
    "        if video_ids:\n",
    "            f.write(f\"Filtrado por IDs de v√≠deo: {', '.join(video_ids)}\\n\")\n",
    "            \n",
    "        f.write(f\"N√∫mero de videos procesados: {metrics['num_videos']}\\n\")\n",
    "        f.write(f\"N√∫mero total de im√°genes: {metrics['num_images']}\\n\")\n",
    "        f.write(f\"N√∫mero total de predicciones: {metrics['num_predictions']}\\n\")\n",
    "        f.write(f\"N√∫mero total de anotaciones GT: {metrics['num_annotations']}\\n\\n\")\n",
    "        \n",
    "        if categories:\n",
    "            f.write(\"CATEGOR√çAS\\n\")\n",
    "            f.write(\"-\" * 80 + \"\\n\")\n",
    "            for cat in categories:\n",
    "                f.write(f\"- {cat}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"ARCHIVOS PROCESADOS\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        for file_pair in processed_files:\n",
    "            f.write(f\"{file_pair}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"M√âTRICAS GLOBALES\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        f.write(f\"mAP (IoU=0.50:0.95): {metrics['mAP']:.4f}\\n\")\n",
    "        f.write(f\"mAP (IoU=0.50): {metrics['mAP_50']:.4f}\\n\")\n",
    "        f.write(f\"mAP (IoU=0.75): {metrics['mAP_75']:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"M√âTRICAS POR TAMA√ëO DE OBJETO\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        f.write(f\"mAP para objetos peque√±os: {metrics['mAP_small']:.4f}\\n\")\n",
    "        f.write(f\"mAP para objetos medianos: {metrics['mAP_medium']:.4f}\\n\")\n",
    "        f.write(f\"mAP para objetos grandes: {metrics['mAP_large']:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"M√âTRICAS DE RECALL\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        f.write(f\"AR dado 1 detecci√≥n por imagen: {metrics['AR_max1']:.4f}\\n\")\n",
    "        f.write(f\"AR dado 10 detecciones por imagen: {metrics['AR_max10']:.4f}\\n\")\n",
    "        f.write(f\"AR dado 100 detecciones por imagen: {metrics['AR_max100']:.4f}\\n\")\n",
    "        f.write(f\"AR para objetos peque√±os: {metrics['AR_small']:.4f}\\n\")\n",
    "        f.write(f\"AR para objetos medianos: {metrics['AR_medium']:.4f}\\n\")\n",
    "        f.write(f\"AR para objetos grandes: {metrics['AR_large']:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.write(\"Fin del informe\\n\")\n",
    "    \n",
    "    print(f\"\\nInforme de resultados guardado en: {os.path.abspath(output_file)}\")\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 21 archivos de predicciones y 21 archivos de ground truth\n",
      "Se emparejaron 21 archivos\n",
      "Procesando: preds_coco_0000.json y gt_coco_0000.json\n",
      "Procesando: preds_coco_0001.json y gt_coco_0001.json\n",
      "Procesando: preds_coco_0002.json y gt_coco_0002.json\n",
      "Procesando: preds_coco_0003.json y gt_coco_0003.json\n",
      "Procesando: preds_coco_0004.json y gt_coco_0004.json\n",
      "Procesando: preds_coco_0005.json y gt_coco_0005.json\n",
      "Procesando: preds_coco_0006.json y gt_coco_0006.json\n",
      "Procesando: preds_coco_0007.json y gt_coco_0007.json\n",
      "Procesando: preds_coco_0008.json y gt_coco_0008.json\n",
      "Procesando: preds_coco_0009.json y gt_coco_0009.json\n",
      "Procesando: preds_coco_0010.json y gt_coco_0010.json\n",
      "Procesando: preds_coco_0011.json y gt_coco_0011.json\n",
      "Procesando: preds_coco_0012.json y gt_coco_0012.json\n",
      "Procesando: preds_coco_0013.json y gt_coco_0013.json\n",
      "Procesando: preds_coco_0014.json y gt_coco_0014.json\n",
      "Procesando: preds_coco_0015.json y gt_coco_0015.json\n",
      "Procesando: preds_coco_0016.json y gt_coco_0016.json\n",
      "Procesando: preds_coco_0017.json y gt_coco_0017.json\n",
      "Procesando: preds_coco_0018.json y gt_coco_0018.json\n",
      "Procesando: preds_coco_0019.json y gt_coco_0019.json\n",
      "Procesando: preds_coco_0020.json y gt_coco_0020.json\n",
      "Datos combinados: 34427 predicciones, 7162 im√°genes, 38275 anotaciones ground truth\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=10.80s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.463\n",
      "\n",
      "Informe de resultados guardado en: /Users/arnaubarrera/Desktop/MSc Computer Vision/C5. Visual Recognition/mcv-c5-group-3/huggingface/week2/instance_segmentation_results.txt\n"
     ]
    }
   ],
   "source": [
    "gt_folder = '/Users/arnaubarrera/Desktop/MSc Computer Vision/C5. Visual Recognition/mcv-c5-group-3/huggingface/week2/Evaluation_off-the-shelf/ground_truth'\n",
    "preds_folder = '/Users/arnaubarrera/Desktop/MSc Computer Vision/C5. Visual Recognition/mcv-c5-group-3/huggingface/week2/Evaluation_off-the-shelf/preds_off-the-shelf'\n",
    "\n",
    "results_global = calculate_global_map_from_files(preds_folder, gt_folder, output_file=\"instance_segmentation_results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 21 archivos de predicciones y 21 archivos de ground truth\n",
      "Filtrando por 1 IDs de v√≠deo especificados\n",
      "Se emparejaron 1 archivos\n",
      "Procesando: preds_coco_0002.json y gt_coco_0002.json\n",
      "Datos combinados: 873 predicciones, 218 im√°genes, 1083 anotaciones ground truth\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.276\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
      "\n",
      "Informe de resultados guardado en: /Users/arnaubarrera/Desktop/MSc Computer Vision/C5. Visual Recognition/mcv-c5-group-3/huggingface/week2/instance_segmentation_results.txt\n"
     ]
    }
   ],
   "source": [
    "results_global = calculate_global_map_from_files(preds_folder, gt_folder, output_file=\"instance_segmentation_results.txt\", video_ids=['0002'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
